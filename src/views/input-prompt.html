<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Voice Input</title>
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <style>
    body {
      margin: 0;
      padding: 0;
      background: transparent;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
        sans-serif;
      overflow: hidden;
    }

    .input-prompt {
      width: 360px;
      height: 80px;
      background: linear-gradient(135deg, rgba(30, 35, 50, 0.95), rgba(45, 50, 70, 0.95));
      border-radius: 16px;
      -webkit-backdrop-filter: blur(25px);
      backdrop-filter: blur(25px);
      border: none;
      box-shadow: 
        0 8px 20px rgba(0, 0, 0, 0.3),
        0 0 0 1px rgba(255, 255, 255, 0.05),
        inset 0 1px 0 rgba(255, 255, 255, 0.1);
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 30px;
      padding: 0 20px;
      transition: all 0.4s cubic-bezier(0.25, 0.8, 0.25, 1);
      opacity: 0;
      transform: translateY(20px) scale(0.95);
      position: relative;
      overflow: hidden;
    }

    .input-prompt.visible {
      opacity: 1;
      transform: translateY(0) scale(1);
    }

    .input-prompt.recording {
      height: 90px;
      box-shadow: 
        0 0 30px rgba(99, 102, 241, 0.3),
        0 8px 20px rgba(0, 0, 0, 0.3),
        0 0 0 1px rgba(99, 102, 241, 0.3),
        inset 0 1px 0 rgba(255, 255, 255, 0.15);
      background: linear-gradient(135deg, rgba(35, 40, 80, 0.95), rgba(50, 55, 100, 0.95));
    }

    .left-section {
      display: flex;
      align-items: center;
      gap: 14px;
      flex: none;
    }

    .right-section {
      display: flex;
      align-items: center;
      gap: 12px;
      flex: none;
    }

    .content-section {
      display: flex;
      flex-direction: column;
      justify-content: center;
      gap: 2px;
      flex: 1;
      min-width: 0;
    }

    .prompt-text {
      color: white;
      font-size: 14px;
      font-weight: 500;
      opacity: 0.9;
      transition: all 0.3s ease;
      text-shadow: 0 1px 2px rgba(0, 0, 0, 0.5);
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
    }

    .wave-container {
      display: flex;
      align-items: center;
      justify-content: center;
      height: 28px;
      gap: 2px;
      width: 120px;
    }

    .wave-bar {
      width: 3px;
      background: linear-gradient(to top, #6366f1, #4f46e5);
      border-radius: 2px;
      transition: all 0.15s cubic-bezier(0.4, 0, 0.2, 1);
      opacity: 0.4;
      box-shadow: 0 0 6px rgba(99, 102, 241, 0.2);
    }

    .wave-bar.active {
      opacity: 1;
      background: linear-gradient(to top, #6366f1, #8b5cf6);
      box-shadow: 0 0 8px rgba(99, 102, 241, 0.4);
    }

    .status-text {
      color: white;
      font-size: 11px;
      font-weight: 400;
      opacity: 0.7;
      display: flex;
      align-items: center;
      justify-content: flex-start;
      text-shadow: 0 1px 2px rgba(0, 0, 0, 0.5);
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
    }

    .microphone-icon {
      font-size: 24px;
      opacity: 0.9;
      color: #6366f1;
      text-shadow: 0 0 8px rgba(99, 102, 241, 0.4);
      transition: all 0.3s ease;
      position: relative;
      flex-shrink: 0;
    }

    .input-prompt.recording .microphone-icon {
      animation: micGlow 2s ease-in-out infinite;
    }

    @keyframes micGlow {
      0%, 100% { 
        transform: scale(1);
        text-shadow: 0 0 10px rgba(99, 102, 241, 0.5);
      }
      50% { 
        transform: scale(1.05);
        text-shadow: 0 0 20px rgba(99, 102, 241, 0.8);
      }
    }

    .material-icons {
      font-family: 'Material Icons';
      font-weight: normal;
      font-style: normal;
      font-size: 28px;
      line-height: 1;
      letter-spacing: normal;
      text-transform: none;
      display: inline-block;
      white-space: nowrap;
      word-wrap: normal;
      direction: ltr;
      -webkit-font-feature-settings: 'liga';
      font-feature-settings: 'liga';
      -webkit-font-smoothing: antialiased;
    }

    .recording-dot {
      width: 10px;
      height: 10px;
      background: linear-gradient(45deg, #f59e0b, #d97706);
      border-radius: 50%;
      margin-left: 8px;
      animation: recordingPulse 1.2s ease-in-out infinite;
      box-shadow: 0 0 8px rgba(245, 158, 11, 0.5);
    }

    @keyframes recordingPulse {
      0% {
        opacity: 1;
        transform: scale(1);
        box-shadow: 0 0 8px rgba(245, 158, 11, 0.5);
      }
      50% {
        opacity: 0.7;
        transform: scale(1.2);
        box-shadow: 0 0 16px rgba(245, 158, 11, 0.8);
      }
      100% {
        opacity: 1;
        transform: scale(1);
        box-shadow: 0 0 8px rgba(245, 158, 11, 0.5);
      }
    }

    .transcription-text {
      position: absolute;
      top: 100%;
      left: 0;
      right: 0;
      margin-top: 8px;
      color: white;
      font-size: 13px;
      font-weight: 500;
      text-align: center;
      padding: 8px 16px;
      background: linear-gradient(135deg, rgba(20, 25, 40, 0.9), rgba(35, 45, 65, 0.9));
      border-radius: 12px;
      backdrop-filter: blur(15px);
      -webkit-backdrop-filter: blur(15px);
      border: 1px solid rgba(255, 255, 255, 0.1);
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
      word-wrap: break-word;
      opacity: 0;
      transition: opacity 0.4s ease;
      text-shadow: 0 1px 2px rgba(0, 0, 0, 0.5);
      line-height: 1.3;
    }

    .transcription-text.visible {
      opacity: 1;
    }

    /* Enhanced hover effect */
    .input-prompt:hover {
      transform: translateY(-1px) scale(1.01);
      box-shadow: 
        0 12px 30px rgba(0, 0, 0, 0.35),
        0 0 0 1px rgba(255, 255, 255, 0.08),
        inset 0 1px 0 rgba(255, 255, 255, 0.15);
    }

    .input-prompt.recording:hover {
      box-shadow: 
        0 0 40px rgba(99, 102, 241, 0.4),
        0 12px 30px rgba(0, 0, 0, 0.35),
        0 0 0 1px rgba(99, 102, 241, 0.4),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }

    /* Subtle animation for non-recording state */
    .input-prompt:not(.recording) {
      animation: breathe 4s ease-in-out infinite;
    }

    @keyframes breathe {
      0%, 100% { 
        box-shadow: 
          0 8px 20px rgba(0, 0, 0, 0.3),
          0 0 0 1px rgba(255, 255, 255, 0.05),
          inset 0 1px 0 rgba(255, 255, 255, 0.1);
      }
      50% { 
        box-shadow: 
          0 12px 30px rgba(0, 0, 0, 0.35),
          0 0 0 1px rgba(255, 255, 255, 0.08),
          inset 0 1px 0 rgba(255, 255, 255, 0.15);
      }
    }
  </style>
</head>
<body>
  <div class="input-prompt" id="inputPrompt">
    <div class="left-section">
      <div class="microphone-icon material-icons">mic</div>
      <div class="content-section">
        <div class="prompt-text" id="promptText">
          Hold Ctrl + Shift to start dictating
        </div>
        <div class="status-text" id="statusText"></div>
      </div>
    </div>
    
    <div class="right-section">
      <div class="wave-container" id="waveContainer">
        <!-- Wave bars will be generated by JavaScript -->
      </div>
    </div>
    
    <div class="transcription-text" id="transcriptionText"></div>
  </div>

  <script>
    const { ipcRenderer } = require("electron");
    const PermissionManager = require("../permission-manager");

    class VoiceInputPrompt {
      constructor() {
        this.isRecording = false;
        this.audioContext = null;
        this.mediaStream = null;
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.analyser = null;
        this.dataArray = null;
        this.animationId = null;
        this.permissionManager = new PermissionManager();

        this.promptElement = document.getElementById("inputPrompt");
        this.promptText = document.getElementById("promptText");
        this.waveContainer = document.getElementById("waveContainer");
        this.statusText = document.getElementById("statusText");
        this.transcriptionText = document.getElementById("transcriptionText");

        this.createWaveBars();
        this.setupEventListeners();
        this.initializePermissions();
      }

      createWaveBars() {
        for (let i = 0; i < 16; i++) {
          const bar = document.createElement("div");
          bar.className = "wave-bar";
          bar.style.height = "3px";
          this.waveContainer.appendChild(bar);
        }
      }

      async initializePermissions() {
        try {
          await this.permissionManager.init();

          // Setup permission change listener
          this.permissionManager.onPermissionChange(
            "microphone",
            (status) => {
              console.log("Microphone permission changed:", status);
              if (status === "denied" && this.isRecording) {
                this.stopRecording();
                this.statusText.textContent = "Microphone permission denied";
              }
            }
          );
        } catch (error) {
          console.error("Failed to initialize permissions:", error);
        }
      }

      setupEventListeners() {
        // Listen for start recording from main process
        ipcRenderer.on("start-recording", async () => {
          if (!this.isRecording) {
            await this.startRecording();
          }
        });

        // Listen for stop recording from main process
        ipcRenderer.on("stop-recording", () => {
          if (this.isRecording) {
            this.stopRecording();
          }
        });

        // Listen for cleanup microphone signal
        ipcRenderer.on("cleanup-microphone", () => {
          console.log("Received cleanup signal from main process");
          this.cleanup();
        });

        // Legacy support for toggle recording
        ipcRenderer.on("toggle-recording", async () => {
          if (!this.isRecording) {
            await this.startRecording();
          } else {
            this.stopRecording();
          }
        });

        // ESC key to cancel recording when window is focused
        document.addEventListener("keydown", (e) => {
          if (e.key === "Escape" && this.isRecording) {
            this.stopRecording();
          }
        });

        // Add window beforeunload event to ensure cleanup
        window.addEventListener("beforeunload", () => {
          this.cleanup();
        });
      }

      async startRecording() {
        if (this.isRecording) return;

        try {
          // Show prompt immediately
          this.promptElement.classList.add("visible");
          this.promptText.textContent = "Checking permissions...";
          this.statusText.textContent = "";

          // Check and request microphone permission
          const permissionResult =
            await this.permissionManager.requestMicrophonePermission(false);

          if (!permissionResult.granted) {
            await this.handlePermissionDenied(permissionResult);
            return;
          }

          this.isRecording = true;
          this.audioChunks = [];

          // Update UI for recording state
          this.promptElement.classList.add("recording");
          this.promptText.textContent = "Listening...";
          this.statusText.innerHTML =
            'Recording <div class="recording-dot"></div>';

          // Create optimized media stream using permission manager
          this.mediaStream = await this.permissionManager.createMediaStream();

          // Setup audio context for visualization
          this.audioContext = new (window.AudioContext ||
            window.webkitAudioContext)();
          const source = this.audioContext.createMediaStreamSource(
            this.mediaStream
          );
          this.analyser = this.audioContext.createAnalyser();
          this.analyser.fftSize = 256;
          source.connect(this.analyser);

          this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);

          // Setup media recorder
          this.mediaRecorder = new MediaRecorder(this.mediaStream, {
            mimeType: "audio/webm;codecs=opus",
          });

          this.mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              this.audioChunks.push(event.data);
            }
          };

          this.mediaRecorder.onstop = () => {
            this.processRecording();
          };

          this.mediaRecorder.start();
          this.startWaveAnimation();
        } catch (error) {
          console.error("Error starting recording:", error);
          await this.handleRecordingError(error);
        }
      }

      stopRecording() {
        if (!this.isRecording) return;

        this.isRecording = false;
        this.promptText.textContent = "Processing...";
        this.statusText.textContent = "Transcribing audio...";

        // Stop media recorder
        if (this.mediaRecorder && this.mediaRecorder.state === "recording") {
          this.mediaRecorder.stop();
        }

        // Force cleanup of media stream and tracks
        this.cleanup();

        this.stopWaveAnimation();
      }

      cleanup() {
        console.log('Starting microphone cleanup...');
        
        // Stop all media tracks
        if (this.mediaStream) {
          console.log('Stopping media stream tracks...');
          this.mediaStream.getTracks().forEach((track) => {
            console.log(`Stopping track: ${track.kind}, state: ${track.readyState}`);
            track.stop();
            console.log(`Track stopped: ${track.kind}, new state: ${track.readyState}`);
          });
          this.mediaStream = null;
          console.log('Media stream cleared');
        }

        // Close audio context
        if (this.audioContext) {
          console.log(`Closing audio context, current state: ${this.audioContext.state}`);
          if (this.audioContext.state !== 'closed') {
            this.audioContext.close().then(() => {
              console.log('Audio context closed successfully');
            }).catch(err => {
              console.error('Error closing audio context:', err);
            });
          }
          this.audioContext = null;
        }

        // Clean up media recorder
        if (this.mediaRecorder) {
          console.log('Cleaning up media recorder...');
          this.mediaRecorder = null;
        }

        // Clean up analyser
        if (this.analyser) {
          console.log('Cleaning up analyser...');
          this.analyser = null;
        }
        
        if (this.dataArray) {
          this.dataArray = null;
        }

        // Reset audio chunks
        this.audioChunks = [];
        
        console.log('Microphone cleanup completed');
      }

      async processRecording() {
        try {
          const audioBlob = new Blob(this.audioChunks, {
            type: "audio/webm",
          });
          const arrayBuffer = await audioBlob.arrayBuffer();
          const audioBuffer = Buffer.from(arrayBuffer);

          const transcription = await ipcRenderer.invoke(
            "transcribe-audio",
            audioBuffer
          );

          if (transcription && transcription.trim()) {
            this.typeText(transcription);
          } else {
            this.statusText.textContent = "No speech detected";
            setTimeout(() => this.hidePrompt(), 2000);
          }
        } catch (error) {
          console.error("Transcription error:", error);
          this.statusText.textContent =
            "Transcription failed - please try again";
          setTimeout(() => this.hidePrompt(), 3000);
        }
      }

      async handlePermissionDenied(permissionResult) {
        this.isRecording = false;

        // Force cleanup of resources
        this.cleanup();

        const statusMessage =
          this.permissionManager.getPermissionStatusText();
        this.statusText.textContent = statusMessage.status;
        this.statusText.style.color = statusMessage.color;

        switch (permissionResult.status) {
          case "denied":
            this.promptText.textContent = "Permission denied";
            break;
          case "no-device":
            this.promptText.textContent = "No microphone found";
            break;
          case "unsupported":
            this.promptText.textContent = "Microphone not supported";
            break;
          case "user-cancelled":
            this.promptText.textContent = "Permission cancelled";
            break;
          default:
            this.promptText.textContent = "Cannot access microphone";
        }

        setTimeout(() => this.hidePrompt(), 3000);
      }

      async handleRecordingError(error) {
        this.isRecording = false;

        // Force cleanup of resources
        this.cleanup();

        let errorMessage = "Recording failed";

        if (
          error.name === "NotAllowedError" ||
          error.name === "PermissionDeniedError"
        ) {
          errorMessage = "Microphone permission denied";
        } else if (error.name === "NotFoundError") {
          errorMessage = "No microphone found";
        } else if (error.name === "NotReadableError") {
          errorMessage = "Microphone is busy";
        } else if (error.name === "OverconstrainedError") {
          errorMessage = "Microphone settings not supported";
        }

        this.promptText.textContent = errorMessage;
        this.statusText.textContent = "Please check your microphone settings";

        setTimeout(() => this.hidePrompt(), 3000);
      }

      async typeText(text) {
        // Send the transcribed text to the active application
        try {
          const result = await ipcRenderer.invoke("type-text", text);

          if (result.success) {
            if (result.method === "direct_typing") {
              console.log("Text typed directly:", text);
              this.statusText.textContent = "Text typed directly";
              this.statusText.style.color = "#00ff00";
              setTimeout(() => this.hidePrompt(), 1500);
            } else if (result.method === "clipboard_textinsert") {
              console.log("Text inserted successfully:", text);
              this.statusText.textContent = result.message || "Text inserted automatically";
              
              // Different colors based on message complexity
              if (result.message && result.message.includes("partially restored")) {
                this.statusText.style.color = "#ffaa00"; // Orange for partial restoration
              } else {
                this.statusText.style.color = "#00ff00"; // Green for full restoration
              }
              
              // Close immediately after successful insertion
              this.hidePrompt();
            } else if (result.method === "clipboard") {
              console.log("Text copied to clipboard:", text);
              this.statusText.textContent = result.message || "Text copied - Press Cmd+V to paste";
              this.statusText.style.color = "#ffaa00";
              setTimeout(() => this.hidePrompt(), 3000);
            }
          }
        } catch (error) {
          console.error("Failed to type text:", error);
          this.statusText.textContent = "Failed to insert text - trying clipboard fallback";
          this.statusText.style.color = "#ff6600";

          // Final fallback: copy to clipboard
          try {
            await navigator.clipboard.writeText(text);
            this.statusText.textContent = "Text copied to clipboard - Press Cmd+V to paste";
            setTimeout(() => this.hidePrompt(), 3000);
          } catch (clipboardError) {
            console.error("Failed to copy to clipboard:", clipboardError);
            this.statusText.textContent = "Error: Could not process text";
            this.statusText.style.color = "#ff0000";
            setTimeout(() => this.hidePrompt(), 3000);
          }
        }
      }

      startWaveAnimation() {
        const bars = this.waveContainer.querySelectorAll(".wave-bar");

        const animate = () => {
          if (!this.isRecording) return;

          if (this.analyser && this.dataArray) {
            this.analyser.getByteFrequencyData(this.dataArray);

            bars.forEach((bar, index) => {
              const dataIndex = Math.floor(
                (index / bars.length) * this.dataArray.length
              );
              const amplitude = this.dataArray[dataIndex] / 255;
              const height = Math.max(3, amplitude * 25);

              bar.style.height = `${height}px`;
              bar.classList.toggle("active", amplitude > 0.1);
            });
          } else {
            // Fallback random animation
            bars.forEach((bar) => {
              const height = Math.random() * 20 + 3;
              bar.style.height = `${height}px`;
              bar.classList.toggle("active", Math.random() > 0.5);
            });
          }

          this.animationId = requestAnimationFrame(animate);
        };

        animate();
      }

      stopWaveAnimation() {
        if (this.animationId) {
          cancelAnimationFrame(this.animationId);
          this.animationId = null;
        }

        // Reset wave bars
        const bars = this.waveContainer.querySelectorAll(".wave-bar");
        bars.forEach((bar) => {
          bar.style.height = "3px";
          bar.classList.remove("active");
        });
      }

      hidePrompt() {
        // Force cleanup of any remaining resources
        this.cleanup();
        
        this.promptElement.classList.remove("visible", "recording");
        this.transcriptionText.classList.remove("visible");
        this.promptText.textContent = "Hold Ctrl + Shift to start dictating";
        this.statusText.textContent = "";
        this.statusText.style.color = "";
        this.transcriptionText.textContent = "";

        // Reset recording state
        this.isRecording = false;

        setTimeout(() => {
          ipcRenderer.invoke("hide-input-prompt");
        }, 300);
      }
    }

    // Initialize when DOM is loaded
    document.addEventListener("DOMContentLoaded", () => {
      new VoiceInputPrompt();
    });
  </script>
</body>
</html>
