<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice Input</title>
  <style>
    body {
      margin: 0;
      padding: 0;
      background: transparent;
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      overflow: hidden;
    }
    
    .input-prompt {
      width: 400px;
      height: 100px;
      background: rgba(0, 0, 0, 0.85);
      border-radius: 12px;
      -webkit-backdrop-filter: blur(20px);
      backdrop-filter: blur(20px);
      border: 1px solid rgba(255, 255, 255, 0.1);
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
      opacity: 0;
      transform: translateY(20px);
    }
    
    .input-prompt.visible {
      opacity: 1;
      transform: translateY(0);
    }
    
    .input-prompt.recording {
      height: 120px;
      box-shadow: 0 0 30px rgba(74, 144, 226, 0.3);
      border-color: rgba(74, 144, 226, 0.5);
    }
    
    .prompt-text {
      color: white;
      font-size: 14px;
      margin-bottom: 12px;
      opacity: 0.8;
      transition: all 0.3s ease;
    }
    
    .wave-container {
      display: flex;
      align-items: center;
      justify-content: center;
      height: 40px;
      gap: 2px;
    }
    
    .wave-bar {
      width: 3px;
      background: linear-gradient(to top, #4a90e2, #7bb3f0);
      border-radius: 2px;
      transition: all 0.1s ease;
      opacity: 0.3;
    }
    
    .wave-bar.active {
      opacity: 1;
    }
    
    .status-text {
      color: white;
      font-size: 12px;
      margin-top: 8px;
      opacity: 0.6;
    }
    
    .microphone-icon {
      font-size: 20px;
      margin-bottom: 8px;
      opacity: 0.6;
    }
    
    .recording-dot {
      width: 8px;
      height: 8px;
      background: #ff4757;
      border-radius: 50%;
      margin-left: 8px;
      animation: pulse 1.5s infinite;
    }
    
    @keyframes pulse {
      0% { opacity: 1; transform: scale(1); }
      50% { opacity: 0.5; transform: scale(1.2); }
      100% { opacity: 1; transform: scale(1); }
    }
    
    .transcription-text {
      color: white;
      font-size: 14px;
      text-align: center;
      padding: 0 20px;
      max-width: 360px;
      word-wrap: break-word;
      opacity: 0;
      transition: opacity 0.3s ease;
    }
    
    .transcription-text.visible {
      opacity: 1;
    }
  </style>
</head>
<body>
  <div class="input-prompt" id="inputPrompt">
    <div class="microphone-icon">ðŸŽ¤</div>
    <div class="prompt-text" id="promptText">Click to start dictating</div>
    
    <div class="wave-container" id="waveContainer">
      <!-- Wave bars will be generated by JavaScript -->
    </div>
    
    <div class="status-text" id="statusText"></div>
    <div class="transcription-text" id="transcriptionText"></div>
  </div>

  <script>
    const { ipcRenderer } = require('electron');
    
    class VoiceInputPrompt {
      constructor() {
        this.isRecording = false;
        this.audioContext = null;
        this.mediaStream = null;
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.analyser = null;
        this.dataArray = null;
        this.animationId = null;
        
        this.promptElement = document.getElementById('inputPrompt');
        this.promptText = document.getElementById('promptText');
        this.waveContainer = document.getElementById('waveContainer');
        this.statusText = document.getElementById('statusText');
        this.transcriptionText = document.getElementById('transcriptionText');
        
        this.createWaveBars();
        this.setupEventListeners();
      }
      
      createWaveBars() {
        for (let i = 0; i < 20; i++) {
          const bar = document.createElement('div');
          bar.className = 'wave-bar';
          bar.style.height = '4px';
          this.waveContainer.appendChild(bar);
        }
      }
      
      setupEventListeners() {
        // Listen for start recording from main process
        ipcRenderer.on('start-recording', () => {
          this.startRecording();
        });
        
        // Global key event listeners
        document.addEventListener('keydown', (e) => {
          if (e.ctrlKey && e.shiftKey && e.key === 'V') {
            if (!this.isRecording) {
              this.startRecording();
            }
          }
        });
        
        document.addEventListener('keyup', (e) => {
          if (e.ctrlKey || e.shiftKey || e.key === 'V') {
            if (this.isRecording) {
              this.stopRecording();
            }
          }
        });
      }
      
      async startRecording() {
        if (this.isRecording) return;
        
        try {
          this.isRecording = true;
          this.audioChunks = [];
          
          // Show prompt
          this.promptElement.classList.add('visible');
          this.promptElement.classList.add('recording');
          this.promptText.textContent = 'Listening...';
          this.statusText.innerHTML = 'Recording <div class="recording-dot"></div>';
          
          // Get microphone access
          this.mediaStream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
              sampleRate: 44100,
              channelCount: 1,
              echoCancellation: true,
              noiseSuppression: true
            }
          });
          
          // Setup audio context for visualization
          this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
          const source = this.audioContext.createMediaStreamSource(this.mediaStream);
          this.analyser = this.audioContext.createAnalyser();
          this.analyser.fftSize = 256;
          source.connect(this.analyser);
          
          this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);
          
          // Setup media recorder
          this.mediaRecorder = new MediaRecorder(this.mediaStream, {
            mimeType: 'audio/webm;codecs=opus'
          });
          
          this.mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              this.audioChunks.push(event.data);
            }
          };
          
          this.mediaRecorder.onstop = () => {
            this.processRecording();
          };
          
          this.mediaRecorder.start();
          this.startWaveAnimation();
          
        } catch (error) {
          console.error('Error starting recording:', error);
          this.statusText.textContent = 'Microphone access denied';
          setTimeout(() => this.hidePrompt(), 2000);
        }
      }
      
      stopRecording() {
        if (!this.isRecording) return;
        
        this.isRecording = false;
        this.promptText.textContent = 'Processing...';
        this.statusText.textContent = 'Transcribing audio...';
        
        if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
          this.mediaRecorder.stop();
        }
        
        if (this.mediaStream) {
          this.mediaStream.getTracks().forEach(track => track.stop());
        }
        
        if (this.audioContext) {
          this.audioContext.close();
        }
        
        this.stopWaveAnimation();
      }
      
      async processRecording() {
        try {
          const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
          const arrayBuffer = await audioBlob.arrayBuffer();
          const audioBuffer = Buffer.from(arrayBuffer);
          
          const transcription = await ipcRenderer.invoke('transcribe-audio', audioBuffer);
          
          if (transcription && transcription.trim()) {
            this.showTranscription(transcription);
            this.typeText(transcription);
          } else {
            this.statusText.textContent = 'No speech detected';
            setTimeout(() => this.hidePrompt(), 2000);
          }
          
        } catch (error) {
          console.error('Transcription error:', error);
          this.statusText.textContent = 'Transcription failed';
          setTimeout(() => this.hidePrompt(), 2000);
        }
      }
      
      showTranscription(text) {
        this.transcriptionText.textContent = text;
        this.transcriptionText.classList.add('visible');
        this.promptText.textContent = 'Transcribed:';
        this.statusText.textContent = '';
        
        setTimeout(() => {
          this.hidePrompt();
        }, 3000);
      }
      
      async typeText(text) {
        // Send the transcribed text to the active application
        // This would require additional implementation to send text to focused app
        console.log('Typing text:', text);
        
        // For now, copy to clipboard
        try {
          await navigator.clipboard.writeText(text);
        } catch (error) {
          console.error('Failed to copy to clipboard:', error);
        }
      }
      
      startWaveAnimation() {
        const bars = this.waveContainer.querySelectorAll('.wave-bar');
        
        const animate = () => {
          if (!this.isRecording) return;
          
          if (this.analyser && this.dataArray) {
            this.analyser.getByteFrequencyData(this.dataArray);
            
            bars.forEach((bar, index) => {
              const dataIndex = Math.floor((index / bars.length) * this.dataArray.length);
              const amplitude = this.dataArray[dataIndex] / 255;
              const height = Math.max(4, amplitude * 40);
              
              bar.style.height = `${height}px`;
              bar.classList.toggle('active', amplitude > 0.1);
            });
          } else {
            // Fallback random animation
            bars.forEach(bar => {
              const height = Math.random() * 30 + 4;
              bar.style.height = `${height}px`;
              bar.classList.toggle('active', Math.random() > 0.5);
            });
          }
          
          this.animationId = requestAnimationFrame(animate);
        };
        
        animate();
      }
      
      stopWaveAnimation() {
        if (this.animationId) {
          cancelAnimationFrame(this.animationId);
          this.animationId = null;
        }
        
        // Reset wave bars
        const bars = this.waveContainer.querySelectorAll('.wave-bar');
        bars.forEach(bar => {
          bar.style.height = '4px';
          bar.classList.remove('active');
        });
      }
      
      hidePrompt() {
        this.promptElement.classList.remove('visible', 'recording');
        this.transcriptionText.classList.remove('visible');
        this.promptText.textContent = 'Click to start dictating';
        this.statusText.textContent = '';
        this.transcriptionText.textContent = '';
        
        setTimeout(() => {
          ipcRenderer.invoke('hide-input-prompt');
        }, 300);
      }
    }
    
    // Initialize when DOM is loaded
    document.addEventListener('DOMContentLoaded', () => {
      new VoiceInputPrompt();
    });
  </script>
</body>
</html>
