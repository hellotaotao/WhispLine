<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Voice Input</title>
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <style>
    body {
      margin: 0;
      padding: 0;
      background: transparent;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
        sans-serif;
      overflow: hidden;
    }

    .input-prompt {
      width: 400px;
      height: 100px;
      background: rgba(0, 0, 0, 0.85);
      border-radius: 12px;
      -webkit-backdrop-filter: blur(20px);
      backdrop-filter: blur(20px);
      border: 1px solid rgba(255, 255, 255, 0.1);
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
      opacity: 0;
      transform: translateY(20px);
    }

    .input-prompt.visible {
      opacity: 1;
      transform: translateY(0);
    }

    .input-prompt.recording {
      height: 120px;
      box-shadow: 0 0 30px rgba(74, 144, 226, 0.3);
      border-color: rgba(74, 144, 226, 0.5);
    }

    .prompt-text {
      color: white;
      font-size: 14px;
      margin-bottom: 12px;
      opacity: 0.8;
      transition: all 0.3s ease;
    }

    .wave-container {
      display: flex;
      align-items: center;
      justify-content: center;
      height: 40px;
      gap: 2px;
    }

    .wave-bar {
      width: 3px;
      background: linear-gradient(to top, #4a90e2, #7bb3f0);
      border-radius: 2px;
      transition: all 0.1s ease;
      opacity: 0.3;
    }

    .wave-bar.active {
      opacity: 1;
    }

    .status-text {
      color: white;
      font-size: 12px;
      margin-top: 8px;
      opacity: 0.6;
    }

    .microphone-icon {
      font-size: 20px;
      margin-bottom: 8px;
      opacity: 0.6;
    }

    .material-icons {
      font-family: 'Material Icons';
      font-weight: normal;
      font-style: normal;
      font-size: 20px;
      line-height: 1;
      letter-spacing: normal;
      text-transform: none;
      display: inline-block;
      white-space: nowrap;
      word-wrap: normal;
      direction: ltr;
      -webkit-font-feature-settings: 'liga';
      font-feature-settings: 'liga';
      -webkit-font-smoothing: antialiased;
    }

    .recording-dot {
      width: 8px;
      height: 8px;
      background: #ff4757;
      border-radius: 50%;
      margin-left: 8px;
      animation: pulse 1.5s infinite;
    }

    @keyframes pulse {
      0% {
        opacity: 1;
        transform: scale(1);
      }
      50% {
        opacity: 0.5;
        transform: scale(1.2);
      }
      100% {
        opacity: 1;
        transform: scale(1);
      }
    }

    .transcription-text {
      color: white;
      font-size: 14px;
      text-align: center;
      padding: 0 20px;
      max-width: 360px;
      word-wrap: break-word;
      opacity: 0;
      transition: opacity 0.3s ease;
    }

    .transcription-text.visible {
      opacity: 1;
    }
  </style>
</head>
<body>
  <div class="input-prompt" id="inputPrompt">
    <div class="microphone-icon material-icons">mic</div>
    <div class="prompt-text" id="promptText">
      Hold Ctrl + Shift to start dictating
    </div>

    <div class="wave-container" id="waveContainer">
      <!-- Wave bars will be generated by JavaScript -->
    </div>

    <div class="status-text" id="statusText"></div>
    <div class="transcription-text" id="transcriptionText"></div>
  </div>

  <script>
    const { ipcRenderer } = require("electron");
    const PermissionManager = require("../permission-manager");

    class VoiceInputPrompt {
      constructor() {
        this.isRecording = false;
        this.audioContext = null;
        this.mediaStream = null;
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.analyser = null;
        this.dataArray = null;
        this.animationId = null;
        this.permissionManager = new PermissionManager();

        this.promptElement = document.getElementById("inputPrompt");
        this.promptText = document.getElementById("promptText");
        this.waveContainer = document.getElementById("waveContainer");
        this.statusText = document.getElementById("statusText");
        this.transcriptionText = document.getElementById("transcriptionText");

        this.createWaveBars();
        this.setupEventListeners();
        this.initializePermissions();
      }

      createWaveBars() {
        for (let i = 0; i < 20; i++) {
          const bar = document.createElement("div");
          bar.className = "wave-bar";
          bar.style.height = "4px";
          this.waveContainer.appendChild(bar);
        }
      }

      async initializePermissions() {
        try {
          await this.permissionManager.init();

          // Setup permission change listener
          this.permissionManager.onPermissionChange(
            "microphone",
            (status) => {
              console.log("Microphone permission changed:", status);
              if (status === "denied" && this.isRecording) {
                this.stopRecording();
                this.statusText.textContent = "Microphone permission denied";
              }
            }
          );
        } catch (error) {
          console.error("Failed to initialize permissions:", error);
        }
      }

      setupEventListeners() {
        // Listen for start recording from main process
        ipcRenderer.on("start-recording", async () => {
          if (!this.isRecording) {
            await this.startRecording();
          }
        });

        // Listen for stop recording from main process
        ipcRenderer.on("stop-recording", () => {
          if (this.isRecording) {
            this.stopRecording();
          }
        });

        // Listen for cleanup microphone signal
        ipcRenderer.on("cleanup-microphone", () => {
          console.log("Received cleanup signal from main process");
          this.cleanup();
        });

        // Legacy support for toggle recording
        ipcRenderer.on("toggle-recording", async () => {
          if (!this.isRecording) {
            await this.startRecording();
          } else {
            this.stopRecording();
          }
        });

        // ESC key to cancel recording when window is focused
        document.addEventListener("keydown", (e) => {
          if (e.key === "Escape" && this.isRecording) {
            this.stopRecording();
          }
        });

        // Add window beforeunload event to ensure cleanup
        window.addEventListener("beforeunload", () => {
          this.cleanup();
        });
      }

      async startRecording() {
        if (this.isRecording) return;

        try {
          // Show prompt immediately
          this.promptElement.classList.add("visible");
          this.promptText.textContent = "Checking permissions...";
          this.statusText.textContent = "";

          // Check and request microphone permission
          const permissionResult =
            await this.permissionManager.requestMicrophonePermission(false);

          if (!permissionResult.granted) {
            await this.handlePermissionDenied(permissionResult);
            return;
          }

          this.isRecording = true;
          this.audioChunks = [];

          // Update UI for recording state
          this.promptElement.classList.add("recording");
          this.promptText.textContent = "Listening...";
          this.statusText.innerHTML =
            'Recording <div class="recording-dot"></div>';

          // Create optimized media stream using permission manager
          this.mediaStream = await this.permissionManager.createMediaStream();

          // Setup audio context for visualization
          this.audioContext = new (window.AudioContext ||
            window.webkitAudioContext)();
          const source = this.audioContext.createMediaStreamSource(
            this.mediaStream
          );
          this.analyser = this.audioContext.createAnalyser();
          this.analyser.fftSize = 256;
          source.connect(this.analyser);

          this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);

          // Setup media recorder
          this.mediaRecorder = new MediaRecorder(this.mediaStream, {
            mimeType: "audio/webm;codecs=opus",
          });

          this.mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              this.audioChunks.push(event.data);
            }
          };

          this.mediaRecorder.onstop = () => {
            this.processRecording();
          };

          this.mediaRecorder.start();
          this.startWaveAnimation();
        } catch (error) {
          console.error("Error starting recording:", error);
          await this.handleRecordingError(error);
        }
      }

      stopRecording() {
        if (!this.isRecording) return;

        this.isRecording = false;
        this.promptText.textContent = "Processing...";
        this.statusText.textContent = "Transcribing audio...";

        // Stop media recorder
        if (this.mediaRecorder && this.mediaRecorder.state === "recording") {
          this.mediaRecorder.stop();
        }

        // Force cleanup of media stream and tracks
        this.cleanup();

        this.stopWaveAnimation();
      }

      cleanup() {
        console.log('Starting microphone cleanup...');
        
        // Stop all media tracks
        if (this.mediaStream) {
          console.log('Stopping media stream tracks...');
          this.mediaStream.getTracks().forEach((track) => {
            console.log(`Stopping track: ${track.kind}, state: ${track.readyState}`);
            track.stop();
            console.log(`Track stopped: ${track.kind}, new state: ${track.readyState}`);
          });
          this.mediaStream = null;
          console.log('Media stream cleared');
        }

        // Close audio context
        if (this.audioContext) {
          console.log(`Closing audio context, current state: ${this.audioContext.state}`);
          if (this.audioContext.state !== 'closed') {
            this.audioContext.close().then(() => {
              console.log('Audio context closed successfully');
            }).catch(err => {
              console.error('Error closing audio context:', err);
            });
          }
          this.audioContext = null;
        }

        // Clean up media recorder
        if (this.mediaRecorder) {
          console.log('Cleaning up media recorder...');
          this.mediaRecorder = null;
        }

        // Clean up analyser
        if (this.analyser) {
          console.log('Cleaning up analyser...');
          this.analyser = null;
        }
        
        if (this.dataArray) {
          this.dataArray = null;
        }

        // Reset audio chunks
        this.audioChunks = [];
        
        console.log('Microphone cleanup completed');
      }

      async processRecording() {
        try {
          const audioBlob = new Blob(this.audioChunks, {
            type: "audio/webm",
          });
          const arrayBuffer = await audioBlob.arrayBuffer();
          const audioBuffer = Buffer.from(arrayBuffer);

          const transcription = await ipcRenderer.invoke(
            "transcribe-audio",
            audioBuffer
          );

          if (transcription && transcription.trim()) {
            this.typeText(transcription);
          } else {
            this.statusText.textContent = "No speech detected";
            setTimeout(() => this.hidePrompt(), 2000);
          }
        } catch (error) {
          console.error("Transcription error:", error);
          this.statusText.textContent =
            "Transcription failed - please try again";
          setTimeout(() => this.hidePrompt(), 3000);
        }
      }

      async handlePermissionDenied(permissionResult) {
        this.isRecording = false;

        // Force cleanup of resources
        this.cleanup();

        const statusMessage =
          this.permissionManager.getPermissionStatusText();
        this.statusText.textContent = statusMessage.status;
        this.statusText.style.color = statusMessage.color;

        switch (permissionResult.status) {
          case "denied":
            this.promptText.textContent = "Permission denied";
            break;
          case "no-device":
            this.promptText.textContent = "No microphone found";
            break;
          case "unsupported":
            this.promptText.textContent = "Microphone not supported";
            break;
          case "user-cancelled":
            this.promptText.textContent = "Permission cancelled";
            break;
          default:
            this.promptText.textContent = "Cannot access microphone";
        }

        setTimeout(() => this.hidePrompt(), 3000);
      }

      async handleRecordingError(error) {
        this.isRecording = false;

        // Force cleanup of resources
        this.cleanup();

        let errorMessage = "Recording failed";

        if (
          error.name === "NotAllowedError" ||
          error.name === "PermissionDeniedError"
        ) {
          errorMessage = "Microphone permission denied";
        } else if (error.name === "NotFoundError") {
          errorMessage = "No microphone found";
        } else if (error.name === "NotReadableError") {
          errorMessage = "Microphone is busy";
        } else if (error.name === "OverconstrainedError") {
          errorMessage = "Microphone settings not supported";
        }

        this.promptText.textContent = errorMessage;
        this.statusText.textContent = "Please check your microphone settings";

        setTimeout(() => this.hidePrompt(), 3000);
      }

      async typeText(text) {
        // Send the transcribed text to the active application
        try {
          const result = await ipcRenderer.invoke("type-text", text);

          if (result.success) {
            if (result.method === "direct_typing") {
              console.log("Text typed directly:", text);
              this.statusText.textContent = "Text typed directly";
              this.statusText.style.color = "#00ff00";
              setTimeout(() => this.hidePrompt(), 1500);
            } else if (result.method === "clipboard_textinsert") {
              console.log("Text inserted successfully:", text);
              this.statusText.textContent = result.message || "Text inserted automatically";
              
              // Different colors based on message complexity
              if (result.message && result.message.includes("partially restored")) {
                this.statusText.style.color = "#ffaa00"; // Orange for partial restoration
              } else {
                this.statusText.style.color = "#00ff00"; // Green for full restoration
              }
              
              // Close immediately after successful insertion
              this.hidePrompt();
            } else if (result.method === "clipboard") {
              console.log("Text copied to clipboard:", text);
              this.statusText.textContent = result.message || "Text copied - Press Cmd+V to paste";
              this.statusText.style.color = "#ffaa00";
              setTimeout(() => this.hidePrompt(), 3000);
            }
          }
        } catch (error) {
          console.error("Failed to type text:", error);
          this.statusText.textContent = "Failed to insert text - trying clipboard fallback";
          this.statusText.style.color = "#ff6600";

          // Final fallback: copy to clipboard
          try {
            await navigator.clipboard.writeText(text);
            this.statusText.textContent = "Text copied to clipboard - Press Cmd+V to paste";
            setTimeout(() => this.hidePrompt(), 3000);
          } catch (clipboardError) {
            console.error("Failed to copy to clipboard:", clipboardError);
            this.statusText.textContent = "Error: Could not process text";
            this.statusText.style.color = "#ff0000";
            setTimeout(() => this.hidePrompt(), 3000);
          }
        }
      }

      startWaveAnimation() {
        const bars = this.waveContainer.querySelectorAll(".wave-bar");

        const animate = () => {
          if (!this.isRecording) return;

          if (this.analyser && this.dataArray) {
            this.analyser.getByteFrequencyData(this.dataArray);

            bars.forEach((bar, index) => {
              const dataIndex = Math.floor(
                (index / bars.length) * this.dataArray.length
              );
              const amplitude = this.dataArray[dataIndex] / 255;
              const height = Math.max(4, amplitude * 40);

              bar.style.height = `${height}px`;
              bar.classList.toggle("active", amplitude > 0.1);
            });
          } else {
            // Fallback random animation
            bars.forEach((bar) => {
              const height = Math.random() * 30 + 4;
              bar.style.height = `${height}px`;
              bar.classList.toggle("active", Math.random() > 0.5);
            });
          }

          this.animationId = requestAnimationFrame(animate);
        };

        animate();
      }

      stopWaveAnimation() {
        if (this.animationId) {
          cancelAnimationFrame(this.animationId);
          this.animationId = null;
        }

        // Reset wave bars
        const bars = this.waveContainer.querySelectorAll(".wave-bar");
        bars.forEach((bar) => {
          bar.style.height = "4px";
          bar.classList.remove("active");
        });
      }

      hidePrompt() {
        // Force cleanup of any remaining resources
        this.cleanup();
        
        this.promptElement.classList.remove("visible", "recording");
        this.transcriptionText.classList.remove("visible");
        this.promptText.textContent = "Hold Ctrl + Shift to start dictating";
        this.statusText.textContent = "";
        this.statusText.style.color = "";
        this.transcriptionText.textContent = "";

        // Reset recording state
        this.isRecording = false;

        setTimeout(() => {
          ipcRenderer.invoke("hide-input-prompt");
        }, 300);
      }
    }

    // Initialize when DOM is loaded
    document.addEventListener("DOMContentLoaded", () => {
      new VoiceInputPrompt();
    });
  </script>
</body>
</html>
